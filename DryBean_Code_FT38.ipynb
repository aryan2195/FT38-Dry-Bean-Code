{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gslO55pArSA"
      },
      "source": [
        "# CSCI218 Group Project: Dry Bean Classification\n",
        "## V3 — SMOTE + PCA + GridSearchCV + Advanced Models\n",
        "\n",
        "**Enhancements over V2:**\n",
        "1. **SMOTE** — Synthetic Minority Over-sampling via `imblearn` Pipeline (no data leakage)\n",
        "2. **PCA** — Dimensionality reduction to remove correlated features\n",
        "3. **GridSearchCV** — Systematic hyperparameter tuning for SVM (C, gamma) and KNN (k)\n",
        "4. **Model Expansion** — XGBoost, LightGBM, and MLP (Neural Network) for complex non-linear patterns\n",
        "5. **Macro-F1** as primary metric for fair 7-class evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtm7rSVIArSG"
      },
      "source": [
        "---\n",
        "## 0. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj5q3KD-ArSI",
        "outputId": "34f4f7ca-e02d-4eaf-c839-4d3b3569b436"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (0.14.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.2.0)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.12/dist-packages (4.6.0)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2026.1.4)\n",
            "Requirement already satisfied: numpy<3,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: sklearn-compat<0.2,>=0.1.5 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (0.1.5)\n",
            "Requirement already satisfied: joblib<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (3.6.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.29.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install ucimlrepo imbalanced-learn xgboost lightgbm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjtjJcMfArSL"
      },
      "source": [
        "---\n",
        "## 1. Imports & Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlR6rNcMArSN",
        "outputId": "b50165e9-6538-4ed4-aea1-f3bd442b1f53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imports and configuration complete.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Use imblearn Pipeline (not sklearn) so SMOTE runs inside each CV fold\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, f1_score, precision_score, recall_score,\n",
        "    classification_report, confusion_matrix\n",
        ")\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Configuration\n",
        "BASE_DIR = os.path.dirname(os.path.abspath(__file__)) if \"__file__\" in globals() else os.getcwd()\n",
        "OUTPUT_DIR = os.path.join(BASE_DIR, \"output\")\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.2\n",
        "N_SPLITS = 5\n",
        "\n",
        "print(\"Imports and configuration complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tR-JGMkiArSQ"
      },
      "source": [
        "---\n",
        "## 2. Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ye_XCO35ArSR",
        "outputId": "49b025fc-01bf-4f81-f8b9-5c72c1483342"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Dry Bean dataset from UCI ML Repository...\n",
            "Loaded successfully via ucimlrepo.\n",
            "Samples: 13611, Features: 16\n",
            "Classes: ['BARBUNYA' 'BOMBAY' 'CALI' 'DERMASON' 'HOROZ' 'SEKER' 'SIRA']\n"
          ]
        }
      ],
      "source": [
        "X, y = None, None\n",
        "\n",
        "try:\n",
        "    from ucimlrepo import fetch_ucirepo\n",
        "    print(\"Loading Dry Bean dataset from UCI ML Repository...\")\n",
        "    dataset = fetch_ucirepo(id=602)\n",
        "    X = dataset.data.features\n",
        "    y = dataset.data.targets.values.ravel()\n",
        "    print(\"Loaded successfully via ucimlrepo.\")\n",
        "except Exception:\n",
        "    local_path = os.path.join(BASE_DIR, \"Dry_Bean_Dataset.csv\")\n",
        "    if os.path.exists(local_path):\n",
        "        print(f\"Loading from local CSV: {local_path}\")\n",
        "        df = pd.read_csv(local_path)\n",
        "        X = df.iloc[:, :-1]\n",
        "        y = df.iloc[:, -1].values\n",
        "    else:\n",
        "        raise FileNotFoundError(\n",
        "            \"Could not load dataset via ucimlrepo and local CSV not found.\\n\"\n",
        "            \"Place Dry_Bean_Dataset.csv next to this notebook, or install ucimlrepo.\"\n",
        "        )\n",
        "\n",
        "print(f\"Samples: {X.shape[0]}, Features: {X.shape[1]}\")\n",
        "print(f\"Classes: {np.unique(y)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ken3gC2jArSS"
      },
      "source": [
        "---\n",
        "## 3. Basic Checks & Class Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSdRgHKrArST",
        "outputId": "0fa9c869-137c-4ace-ad89-b2c0d66a2cf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values: 0\n",
            "\n",
            "Class distribution (before SMOTE):\n",
            "  BARBUNYA: 1322\n",
            "  BOMBAY: 522\n",
            "  CALI: 1630\n",
            "  DERMASON: 3546\n",
            "  HOROZ: 1928\n",
            "  SEKER: 2027\n",
            "  SIRA: 2636\n"
          ]
        }
      ],
      "source": [
        "# Missing values\n",
        "missing = int(pd.DataFrame(X).isnull().sum().sum())\n",
        "print(f\"Missing values: {missing}\")\n",
        "if missing > 0:\n",
        "    X = pd.DataFrame(X).fillna(pd.DataFrame(X).median())\n",
        "    print(\"Filled missing values with median.\")\n",
        "\n",
        "# Class distribution\n",
        "class_counts_before = pd.Series(y).value_counts().sort_index()\n",
        "print(\"\\nClass distribution (before SMOTE):\")\n",
        "for cls, cnt in class_counts_before.items():\n",
        "    print(f\"  {cls}: {cnt}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3sDSf_IArSW"
      },
      "source": [
        "---\n",
        "## 4. Encode Labels & Train/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lo0sFuN5ArSW",
        "outputId": "f4400be5-801a-4b31-9957-c8e466a1ec73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded classes: {'BARBUNYA': 0, 'BOMBAY': 1, 'CALI': 2, 'DERMASON': 3, 'HOROZ': 4, 'SEKER': 5, 'SIRA': 6}\n",
            "Train: 10888 samples\n",
            "Test:  2723 samples\n"
          ]
        }
      ],
      "source": [
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "class_names = le.classes_\n",
        "print(f\"Encoded classes: {dict(zip(class_names, range(len(class_names))))}\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded,\n",
        "    test_size=TEST_SIZE,\n",
        "    random_state=RANDOM_STATE,\n",
        "    stratify=y_encoded\n",
        ")\n",
        "print(f\"Train: {X_train.shape[0]} samples\")\n",
        "print(f\"Test:  {X_test.shape[0]} samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKmWJHbFArSY"
      },
      "source": [
        "---\n",
        "## 5. Address Imbalance — SMOTE Visualisation\n",
        "\n",
        "SMOTE (Synthetic Minority Over-sampling Technique) generates synthetic samples for minority classes like **BOMBAY** (only 522 samples vs 3546 for DERMASON). Inside the pipeline, SMOTE is applied only to training folds — the test set remains untouched."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aL9_I2vMArSY",
        "outputId": "11301d4a-8809-4446-9ac7-3df9a743bcf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples before SMOTE: 10888\n",
            "Training samples after  SMOTE: 19859\n"
          ]
        }
      ],
      "source": [
        "smote_vis = SMOTE(random_state=RANDOM_STATE)\n",
        "scaler_vis = StandardScaler()\n",
        "X_train_scaled_vis = scaler_vis.fit_transform(X_train)\n",
        "X_train_smote_vis, y_train_smote_vis = smote_vis.fit_resample(X_train_scaled_vis, y_train)\n",
        "\n",
        "counts_before = pd.Series(y_train).value_counts().sort_index()\n",
        "counts_after  = pd.Series(y_train_smote_vis).value_counts().sort_index()\n",
        "labels = [class_names[i] for i in counts_before.index]\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "axes[0].bar(labels, counts_before.values, edgecolor=\"black\", color=\"steelblue\")\n",
        "axes[0].set_title(\"Class Distribution \\u2014 Before SMOTE (Train Set)\")\n",
        "axes[0].set_xlabel(\"Bean Class\"); axes[0].set_ylabel(\"Count\")\n",
        "axes[0].tick_params(axis=\"x\", rotation=30)\n",
        "\n",
        "axes[1].bar(labels, counts_after.values, edgecolor=\"black\", color=\"seagreen\")\n",
        "axes[1].set_title(\"Class Distribution \\u2014 After SMOTE (Train Set)\")\n",
        "axes[1].set_xlabel(\"Bean Class\"); axes[1].set_ylabel(\"Count\")\n",
        "axes[1].tick_params(axis=\"x\", rotation=30)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, \"smote_class_distribution.png\"), dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Training samples before SMOTE: {X_train.shape[0]}\")\n",
        "print(f\"Training samples after  SMOTE: {X_train_smote_vis.shape[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfUnCYjNArSa"
      },
      "source": [
        "---\n",
        "## 6. Advanced Feature Engineering — PCA (Dimensionality Reduction)\n",
        "\n",
        "Many of the 16 features are highly correlated (e.g. Area vs Perimeter, MajorAxisLength vs MinorAxisLength). PCA projects the data onto orthogonal principal components, removing redundancy while retaining >= 95% of the variance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARSpc3NVArSa",
        "outputId": "38cd243e-4c1f-40a2-8522-44df677b4a8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original features:          16\n",
            "Components for 95% variance: 4\n",
            "Variance retained:          0.9505\n"
          ]
        }
      ],
      "source": [
        "# Fit PCA on all components to analyse variance\n",
        "pca_full = PCA(random_state=RANDOM_STATE)\n",
        "pca_full.fit(X_train_scaled_vis)  # fit on scaled (non-SMOTE) training data\n",
        "\n",
        "cumulative_variance = np.cumsum(pca_full.explained_variance_ratio_)\n",
        "n_components_95 = int(np.argmax(cumulative_variance >= 0.95) + 1)\n",
        "\n",
        "print(f\"Original features:          {X_train.shape[1]}\")\n",
        "print(f\"Components for 95% variance: {n_components_95}\")\n",
        "print(f\"Variance retained:          {cumulative_variance[n_components_95 - 1]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7An2jXVsArSb"
      },
      "outputs": [],
      "source": [
        "# Explained variance plot\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "ax.bar(range(1, len(pca_full.explained_variance_ratio_) + 1),\n",
        "       pca_full.explained_variance_ratio_, alpha=0.6,\n",
        "       label=\"Individual\", color=\"steelblue\", edgecolor=\"black\")\n",
        "ax.step(range(1, len(cumulative_variance) + 1), cumulative_variance,\n",
        "        where=\"mid\", label=\"Cumulative\", color=\"darkorange\", linewidth=2)\n",
        "ax.axhline(y=0.95, color=\"red\", linestyle=\"--\", label=\"95% threshold\")\n",
        "ax.axvline(x=n_components_95, color=\"green\", linestyle=\"--\", alpha=0.7,\n",
        "           label=f\"n_components = {n_components_95}\")\n",
        "ax.set_xlabel(\"Principal Component\")\n",
        "ax.set_ylabel(\"Explained Variance Ratio\")\n",
        "ax.set_title(\"PCA \\u2014 Explained Variance Analysis\")\n",
        "ax.legend()\n",
        "ax.set_xticks(range(1, len(pca_full.explained_variance_ratio_) + 1))\n",
        "ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.4)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, \"pca_explained_variance.png\"), dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5C0-iq2ArSb"
      },
      "outputs": [],
      "source": [
        "# Feature correlation heatmap (before PCA) — shows why PCA helps\n",
        "corr_matrix = pd.DataFrame(X_train_scaled_vis, columns=X.columns).corr()\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "im = ax.imshow(corr_matrix.values, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
        "ax.set_xticks(range(len(X.columns)))\n",
        "ax.set_yticks(range(len(X.columns)))\n",
        "ax.set_xticklabels(X.columns, rotation=45, ha=\"right\", fontsize=8)\n",
        "ax.set_yticklabels(X.columns, fontsize=8)\n",
        "ax.set_title(\"Feature Correlation Matrix (before PCA)\")\n",
        "plt.colorbar(im, ax=ax)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, \"correlation_matrix_before_pca.png\"), dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAV_phFdArSb"
      },
      "source": [
        "---\n",
        "## 7. Systematic Optimisation — GridSearchCV\n",
        "\n",
        "We use `GridSearchCV` with `imblearn.Pipeline` (SMOTE inside each CV fold) to find:\n",
        "- **SVM**: optimal `C` and `gamma`\n",
        "- **KNN**: optimal `k` (n_neighbors) and weighting scheme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlffJj2wArSc",
        "outputId": "26828947-5a17-47f6-9fd9-d0441d7af540"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM GridSearchCV (C, gamma)...\n",
            "  Best params:      {'clf__C': 10, 'clf__gamma': 0.1}\n",
            "  Best CV macro-F1: 0.8962\n"
          ]
        }
      ],
      "source": [
        "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
        "\n",
        "# --- SVM GridSearch ---\n",
        "print(\"SVM GridSearchCV (C, gamma)...\")\n",
        "svm_pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"pca\",    PCA(n_components=n_components_95, random_state=RANDOM_STATE)),\n",
        "    (\"smote\",  SMOTE(random_state=RANDOM_STATE)),\n",
        "    (\"clf\",    SVC(kernel=\"rbf\", random_state=RANDOM_STATE))\n",
        "])\n",
        "\n",
        "svm_param_grid = {\n",
        "    \"clf__C\":     [0.1, 1, 10, 100],\n",
        "    \"clf__gamma\": [\"scale\", \"auto\", 0.01, 0.1]\n",
        "}\n",
        "\n",
        "svm_grid = GridSearchCV(\n",
        "    svm_pipeline, svm_param_grid,\n",
        "    cv=cv, scoring=\"f1_macro\", n_jobs=-1, verbose=0\n",
        ")\n",
        "svm_grid.fit(X_train, y_train)\n",
        "\n",
        "print(f\"  Best params:      {svm_grid.best_params_}\")\n",
        "print(f\"  Best CV macro-F1: {svm_grid.best_score_:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwC_DeSkArSc",
        "outputId": "2060764c-9c3c-4f37-f8df-aa4f96d2f154"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN GridSearchCV (n_neighbors, weights)...\n",
            "  Best params:      {'clf__n_neighbors': 21, 'clf__weights': 'uniform'}\n",
            "  Best CV macro-F1: 0.8860\n"
          ]
        }
      ],
      "source": [
        "# --- KNN GridSearch ---\n",
        "print(\"KNN GridSearchCV (n_neighbors, weights)...\")\n",
        "knn_pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"pca\",    PCA(n_components=n_components_95, random_state=RANDOM_STATE)),\n",
        "    (\"smote\",  SMOTE(random_state=RANDOM_STATE)),\n",
        "    (\"clf\",    KNeighborsClassifier())\n",
        "])\n",
        "\n",
        "knn_param_grid = {\n",
        "    \"clf__n_neighbors\": [3, 5, 7, 9, 11, 15, 21],\n",
        "    \"clf__weights\":     [\"uniform\", \"distance\"]\n",
        "}\n",
        "\n",
        "knn_grid = GridSearchCV(\n",
        "    knn_pipeline, knn_param_grid,\n",
        "    cv=cv, scoring=\"f1_macro\", n_jobs=-1, verbose=0\n",
        ")\n",
        "knn_grid.fit(X_train, y_train)\n",
        "\n",
        "print(f\"  Best params:      {knn_grid.best_params_}\")\n",
        "print(f\"  Best CV macro-F1: {knn_grid.best_score_:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SaWPCQrArSd"
      },
      "outputs": [],
      "source": [
        "# GridSearch results visualisation\n",
        "svm_results = pd.DataFrame(svm_grid.cv_results_)\n",
        "C_values = svm_param_grid[\"clf__C\"]\n",
        "gamma_values = [str(g) for g in svm_param_grid[\"clf__gamma\"]]\n",
        "scores_matrix = np.zeros((len(C_values), len(gamma_values)))\n",
        "for idx, row in svm_results.iterrows():\n",
        "    c_idx = C_values.index(row[\"param_clf__C\"])\n",
        "    g_idx = gamma_values.index(str(row[\"param_clf__gamma\"]))\n",
        "    scores_matrix[c_idx, g_idx] = row[\"mean_test_score\"]\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
        "\n",
        "# SVM heatmap\n",
        "im0 = axes[0].imshow(scores_matrix, cmap=\"YlOrRd\", aspect=\"auto\")\n",
        "axes[0].set_xticks(range(len(gamma_values)))\n",
        "axes[0].set_yticks(range(len(C_values)))\n",
        "axes[0].set_xticklabels(gamma_values)\n",
        "axes[0].set_yticklabels(C_values)\n",
        "axes[0].set_xlabel(\"gamma\"); axes[0].set_ylabel(\"C\")\n",
        "axes[0].set_title(\"SVM GridSearchCV \\u2014 macro-F1 Scores\")\n",
        "for i in range(len(C_values)):\n",
        "    for j in range(len(gamma_values)):\n",
        "        axes[0].text(j, i, f\"{scores_matrix[i, j]:.3f}\",\n",
        "                     ha=\"center\", va=\"center\", fontsize=9, fontweight=\"bold\")\n",
        "plt.colorbar(im0, ax=axes[0])\n",
        "\n",
        "# KNN line plot\n",
        "knn_results = pd.DataFrame(knn_grid.cv_results_)\n",
        "for weight in [\"uniform\", \"distance\"]:\n",
        "    mask = knn_results[\"param_clf__weights\"] == weight\n",
        "    subset = knn_results[mask].sort_values(\"param_clf__n_neighbors\")\n",
        "    axes[1].plot(subset[\"param_clf__n_neighbors\"], subset[\"mean_test_score\"],\n",
        "                 marker=\"o\", label=f\"weights={weight}\", linewidth=2)\n",
        "    axes[1].fill_between(\n",
        "        subset[\"param_clf__n_neighbors\"],\n",
        "        subset[\"mean_test_score\"] - subset[\"std_test_score\"],\n",
        "        subset[\"mean_test_score\"] + subset[\"std_test_score\"],\n",
        "        alpha=0.15\n",
        "    )\n",
        "axes[1].set_xlabel(\"k (n_neighbors)\"); axes[1].set_ylabel(\"CV macro-F1\")\n",
        "axes[1].set_title(\"KNN GridSearchCV \\u2014 macro-F1 vs k\")\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, linestyle=\"--\", alpha=0.5)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, \"gridsearch_results.png\"), dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3P8Kcp0ArSd"
      },
      "source": [
        "---\n",
        "## 8. Model Training — All Models (PCA + SMOTE + Tuned Hyperparameters)\n",
        "\n",
        "We train 7 models total:\n",
        "1. **Logistic Regression** — linear baseline\n",
        "2. **SVM (RBF, tuned)** — best C/gamma from GridSearchCV\n",
        "3. **KNN (tuned)** — best k/weights from GridSearchCV\n",
        "4. **Random Forest** — ensemble of decision trees\n",
        "5. **XGBoost** — gradient boosting\n",
        "6. **LightGBM** — fast gradient boosting\n",
        "7. **MLP (Neural Network)** — deep learning for non-linear patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZdXybrtArSe",
        "outputId": "94a48d3c-fb0e-4a01-99eb-1a44088000f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models to train: 7\n",
            "  - Logistic Regression\n",
            "  - SVM (RBF, tuned)\n",
            "  - KNN (k=21, tuned)\n",
            "  - Random Forest\n",
            "  - XGBoost\n",
            "  - LightGBM\n",
            "  - MLP (Neural Network)\n"
          ]
        }
      ],
      "source": [
        "best_svm_C     = svm_grid.best_params_[\"clf__C\"]\n",
        "best_svm_gamma = svm_grid.best_params_[\"clf__gamma\"]\n",
        "best_knn_k     = knn_grid.best_params_[\"clf__n_neighbors\"]\n",
        "best_knn_w     = knn_grid.best_params_[\"clf__weights\"]\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"pca\",    PCA(n_components=n_components_95, random_state=RANDOM_STATE)),\n",
        "        (\"smote\",  SMOTE(random_state=RANDOM_STATE)),\n",
        "        (\"clf\",    LogisticRegression(max_iter=3000, random_state=RANDOM_STATE))\n",
        "    ]),\n",
        "    \"SVM (RBF, tuned)\": Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"pca\",    PCA(n_components=n_components_95, random_state=RANDOM_STATE)),\n",
        "        (\"smote\",  SMOTE(random_state=RANDOM_STATE)),\n",
        "        (\"clf\",    SVC(kernel=\"rbf\", C=best_svm_C, gamma=best_svm_gamma,\n",
        "                       random_state=RANDOM_STATE))\n",
        "    ]),\n",
        "    f\"KNN (k={best_knn_k}, tuned)\": Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"pca\",    PCA(n_components=n_components_95, random_state=RANDOM_STATE)),\n",
        "        (\"smote\",  SMOTE(random_state=RANDOM_STATE)),\n",
        "        (\"clf\",    KNeighborsClassifier(n_neighbors=best_knn_k, weights=best_knn_w))\n",
        "    ]),\n",
        "    \"Random Forest\": Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"pca\",    PCA(n_components=n_components_95, random_state=RANDOM_STATE)),\n",
        "        (\"smote\",  SMOTE(random_state=RANDOM_STATE)),\n",
        "        (\"clf\",    RandomForestClassifier(\n",
        "                       n_estimators=300,\n",
        "                       class_weight=\"balanced\",\n",
        "                       random_state=RANDOM_STATE,\n",
        "                       n_jobs=-1\n",
        "                   ))\n",
        "    ]),\n",
        "    \"XGBoost\": Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"pca\",    PCA(n_components=n_components_95, random_state=RANDOM_STATE)),\n",
        "        (\"smote\",  SMOTE(random_state=RANDOM_STATE)),\n",
        "        (\"clf\",    XGBClassifier(\n",
        "                       n_estimators=300,\n",
        "                       learning_rate=0.1,\n",
        "                       max_depth=6,\n",
        "                       use_label_encoder=False,\n",
        "                       eval_metric=\"mlogloss\",\n",
        "                       random_state=RANDOM_STATE,\n",
        "                       n_jobs=-1\n",
        "                   ))\n",
        "    ]),\n",
        "    \"LightGBM\": Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"pca\",    PCA(n_components=n_components_95, random_state=RANDOM_STATE)),\n",
        "        (\"smote\",  SMOTE(random_state=RANDOM_STATE)),\n",
        "        (\"clf\",    LGBMClassifier(\n",
        "                       n_estimators=300,\n",
        "                       learning_rate=0.1,\n",
        "                       max_depth=6,\n",
        "                       class_weight=\"balanced\",\n",
        "                       random_state=RANDOM_STATE,\n",
        "                       n_jobs=-1,\n",
        "                       verbose=-1\n",
        "                   ))\n",
        "    ]),\n",
        "    \"MLP (Neural Network)\": Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"pca\",    PCA(n_components=n_components_95, random_state=RANDOM_STATE)),\n",
        "        (\"smote\",  SMOTE(random_state=RANDOM_STATE)),\n",
        "        (\"clf\",    MLPClassifier(\n",
        "                       hidden_layer_sizes=(128, 64, 32),\n",
        "                       activation=\"relu\",\n",
        "                       solver=\"adam\",\n",
        "                       max_iter=500,\n",
        "                       early_stopping=True,\n",
        "                       validation_fraction=0.1,\n",
        "                       random_state=RANDOM_STATE\n",
        "                   ))\n",
        "    ]),\n",
        "}\n",
        "\n",
        "print(f\"Models to train: {len(models)}\")\n",
        "for name in models:\n",
        "    print(f\"  - {name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0SoiIuyArSf",
        "outputId": "1cd7b623-1549-41dc-cb56-3f8fb1e68fd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training: Logistic Regression\n",
            "  CV macro-F1:        0.8880 (+/- 0.0028)\n",
            "  Test Accuracy:      0.8840\n",
            "  Test F1 (macro):    0.8888\n",
            "  Test F1 (weighted): 0.8839\n",
            "\n",
            "Training: SVM (RBF, tuned)\n",
            "  CV macro-F1:        0.8962 (+/- 0.0037)\n",
            "  Test Accuracy:      0.8924\n",
            "  Test F1 (macro):    0.8959\n",
            "  Test F1 (weighted): 0.8920\n",
            "\n",
            "Training: KNN (k=21, tuned)\n",
            "  CV macro-F1:        0.8860 (+/- 0.0055)\n",
            "  Test Accuracy:      0.8854\n",
            "  Test F1 (macro):    0.8893\n",
            "  Test F1 (weighted): 0.8852\n",
            "\n",
            "Training: Random Forest\n",
            "  CV macro-F1:        0.8841 (+/- 0.0015)\n",
            "  Test Accuracy:      0.8869\n",
            "  Test F1 (macro):    0.8897\n",
            "  Test F1 (weighted): 0.8864\n",
            "\n",
            "Training: XGBoost\n",
            "  CV macro-F1:        0.8830 (+/- 0.0057)\n",
            "  Test Accuracy:      0.8810\n",
            "  Test F1 (macro):    0.8835\n",
            "  Test F1 (weighted): 0.8809\n",
            "\n",
            "Training: LightGBM\n",
            "  CV macro-F1:        0.8787 (+/- 0.0025)\n",
            "  Test Accuracy:      0.8788\n",
            "  Test F1 (macro):    0.8828\n",
            "  Test F1 (weighted): 0.8786\n",
            "\n",
            "Training: MLP (Neural Network)\n",
            "  CV macro-F1:        0.8938 (+/- 0.0031)\n",
            "  Test Accuracy:      0.8924\n",
            "  Test F1 (macro):    0.8957\n",
            "  Test F1 (weighted): 0.8920\n"
          ]
        }
      ],
      "source": [
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining: {name}\")\n",
        "\n",
        "    # CV score on TRAIN ONLY — SMOTE applied inside each fold automatically\n",
        "    cv_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring=\"f1_macro\")\n",
        "\n",
        "    # Fit on full training set, evaluate on untouched test set\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    acc          = accuracy_score(y_test, y_pred)\n",
        "    f1_macro     = f1_score(y_test, y_pred, average=\"macro\")\n",
        "    f1_weighted  = f1_score(y_test, y_pred, average=\"weighted\")\n",
        "    prec_macro   = precision_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
        "    rec_macro    = recall_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
        "\n",
        "    results[name] = {\n",
        "        \"cv_f1_macro_mean\":     float(cv_scores.mean()),\n",
        "        \"cv_f1_macro_std\":      float(cv_scores.std()),\n",
        "        \"test_accuracy\":        float(acc),\n",
        "        \"test_f1_macro\":        float(f1_macro),\n",
        "        \"test_f1_weighted\":     float(f1_weighted),\n",
        "        \"test_precision_macro\": float(prec_macro),\n",
        "        \"test_recall_macro\":    float(rec_macro),\n",
        "        \"y_pred\":               y_pred,\n",
        "        \"model\":                model\n",
        "    }\n",
        "\n",
        "    print(f\"  CV macro-F1:        {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
        "    print(f\"  Test Accuracy:      {acc:.4f}\")\n",
        "    print(f\"  Test F1 (macro):    {f1_macro:.4f}\")\n",
        "    print(f\"  Test F1 (weighted): {f1_weighted:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Cu06aCaArSg",
        "outputId": "cd4873ad-e0e8-4728-c494-f9e8d6d128d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "BEST MODEL (by CV macro-F1): SVM (RBF, tuned)\n",
            "CV macro-F1:   0.8962\n",
            "Test Accuracy: 0.8924\n",
            "Test macro-F1: 0.8959\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Best model selection\n",
        "best_model_name = max(results, key=lambda k: results[k][\"cv_f1_macro_mean\"])\n",
        "best = results[best_model_name]\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(f\"BEST MODEL (by CV macro-F1): {best_model_name}\")\n",
        "print(f\"CV macro-F1:   {best['cv_f1_macro_mean']:.4f}\")\n",
        "print(f\"Test Accuracy: {best['test_accuracy']:.4f}\")\n",
        "print(f\"Test macro-F1: {best['test_f1_macro']:.4f}\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B--hVhWPArSi"
      },
      "source": [
        "---\n",
        "## 9. Confusion Matrices — All Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7riycAeArSi"
      },
      "outputs": [],
      "source": [
        "n_models = len(results)\n",
        "n_cols = 4\n",
        "n_rows = (n_models + n_cols - 1) // n_cols\n",
        "\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(7 * n_cols, 6 * n_rows))\n",
        "axes_flat = axes.flatten() if n_models > 1 else [axes]\n",
        "\n",
        "for idx, (name, r) in enumerate(results.items()):\n",
        "    ax = axes_flat[idx]\n",
        "    cm = confusion_matrix(y_test, r[\"y_pred\"])\n",
        "    im = ax.imshow(cm, cmap=\"Blues\")\n",
        "    ax.set_title(f\"{name}\", fontsize=10, fontweight=\"bold\")\n",
        "    ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"Actual\")\n",
        "    ax.set_xticks(range(len(class_names)))\n",
        "    ax.set_yticks(range(len(class_names)))\n",
        "    ax.set_xticklabels(class_names, rotation=30, ha=\"right\", fontsize=7)\n",
        "    ax.set_yticklabels(class_names, fontsize=7)\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\", fontsize=6,\n",
        "                    color=\"white\" if cm[i, j] > cm.max() / 2 else \"black\")\n",
        "    plt.colorbar(im, ax=ax)\n",
        "\n",
        "# Hide unused subplots\n",
        "for idx in range(n_models, len(axes_flat)):\n",
        "    axes_flat[idx].set_visible(False)\n",
        "\n",
        "plt.suptitle(\"Confusion Matrices \\u2014 All Models (PCA + SMOTE + Tuned)\",\n",
        "             fontsize=14, fontweight=\"bold\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, \"confusion_matrices_all.png\"), dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8dtaBzuArSj"
      },
      "source": [
        "---\n",
        "## 10. Classification Report (Best Model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "346v4AmiArSj",
        "outputId": "efea8d61-6d00-4a01-d904-988db405b235"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Model: SVM (RBF, tuned)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    BARBUNYA       0.83      0.72      0.77       265\n",
            "      BOMBAY       1.00      1.00      1.00       104\n",
            "        CALI       0.81      0.87      0.84       326\n",
            "    DERMASON       0.92      0.90      0.91       709\n",
            "       HOROZ       0.96      0.95      0.96       386\n",
            "       SEKER       0.92      0.96      0.94       406\n",
            "        SIRA       0.84      0.87      0.85       527\n",
            "\n",
            "    accuracy                           0.89      2723\n",
            "   macro avg       0.90      0.90      0.90      2723\n",
            "weighted avg       0.89      0.89      0.89      2723\n",
            "\n",
            "Saved: classification_report_best.txt\n"
          ]
        }
      ],
      "source": [
        "report = classification_report(y_test, best[\"y_pred\"], target_names=class_names, zero_division=0)\n",
        "\n",
        "print(f\"Best Model: {best_model_name}\\n\")\n",
        "print(report)\n",
        "\n",
        "with open(os.path.join(OUTPUT_DIR, \"classification_report_best.txt\"), \"w\") as f:\n",
        "    f.write(f\"Best Model (by CV macro-F1): {best_model_name}\\n\")\n",
        "    f.write(f\"CV macro-F1 mean: {best['cv_f1_macro_mean']:.4f} (std {best['cv_f1_macro_std']:.4f})\\n\")\n",
        "    f.write(f\"Test Accuracy: {best['test_accuracy']:.4f}\\n\")\n",
        "    f.write(f\"Test macro-F1: {best['test_f1_macro']:.4f}\\n\")\n",
        "    f.write(f\"Test weighted-F1: {best['test_f1_weighted']:.4f}\\n\\n\")\n",
        "    f.write(report)\n",
        "print(\"Saved: classification_report_best.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNL4tmQMArSj"
      },
      "source": [
        "---\n",
        "## 11. Model Comparison Chart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJGFwLaFArSj"
      },
      "outputs": [],
      "source": [
        "model_names  = list(results.keys())\n",
        "cv_means     = [results[n][\"cv_f1_macro_mean\"] for n in model_names]\n",
        "test_f1      = [results[n][\"test_f1_macro\"]    for n in model_names]\n",
        "test_acc     = [results[n][\"test_accuracy\"]     for n in model_names]\n",
        "\n",
        "x = np.arange(len(model_names))\n",
        "width = 0.25\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "bars1 = ax.bar(x - width, cv_means, width, label=\"CV macro-F1 (mean)\",\n",
        "               color=\"steelblue\", edgecolor=\"black\")\n",
        "bars2 = ax.bar(x,         test_f1,  width, label=\"Test macro-F1\",\n",
        "               color=\"seagreen\", edgecolor=\"black\")\n",
        "bars3 = ax.bar(x + width, test_acc, width, label=\"Test Accuracy\",\n",
        "               color=\"darkorange\", edgecolor=\"black\")\n",
        "\n",
        "ax.set_title(\"Model Comparison (PCA + SMOTE + GridSearchCV)\",\n",
        "             fontsize=13, fontweight=\"bold\")\n",
        "ax.set_ylabel(\"Score\")\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(model_names, fontsize=8, rotation=15, ha=\"right\")\n",
        "ax.set_ylim(0.85, 1.01)\n",
        "ax.legend()\n",
        "ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
        "\n",
        "for bar in [*bars1, *bars2, *bars3]:\n",
        "    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.001,\n",
        "            f\"{bar.get_height():.3f}\", ha=\"center\", va=\"bottom\", fontsize=7)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, \"model_comparison.png\"), dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lL1Yg-0gArSk"
      },
      "source": [
        "---\n",
        "## 12. Results Summary Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "av3_1wyBArSl",
        "outputId": "7e27f000-ac40-4711-c6cc-1adfb6a40c64"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7c35823417c0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_82694_row1_col1, #T_82694_row1_col3, #T_82694_row1_col6, #T_82694_row6_col3 {\n",
              "  background-color: lightgreen;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_82694\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_82694_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
              "      <th id=\"T_82694_level0_col1\" class=\"col_heading level0 col1\" >CV_MacroF1_Mean</th>\n",
              "      <th id=\"T_82694_level0_col2\" class=\"col_heading level0 col2\" >CV_MacroF1_Std</th>\n",
              "      <th id=\"T_82694_level0_col3\" class=\"col_heading level0 col3\" >Test_Accuracy</th>\n",
              "      <th id=\"T_82694_level0_col4\" class=\"col_heading level0 col4\" >Test_Precision_Macro</th>\n",
              "      <th id=\"T_82694_level0_col5\" class=\"col_heading level0 col5\" >Test_Recall_Macro</th>\n",
              "      <th id=\"T_82694_level0_col6\" class=\"col_heading level0 col6\" >Test_F1_Macro</th>\n",
              "      <th id=\"T_82694_level0_col7\" class=\"col_heading level0 col7\" >Test_F1_Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_82694_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_82694_row0_col0\" class=\"data row0 col0\" >Logistic Regression</td>\n",
              "      <td id=\"T_82694_row0_col1\" class=\"data row0 col1\" >0.887951</td>\n",
              "      <td id=\"T_82694_row0_col2\" class=\"data row0 col2\" >0.002771</td>\n",
              "      <td id=\"T_82694_row0_col3\" class=\"data row0 col3\" >0.883952</td>\n",
              "      <td id=\"T_82694_row0_col4\" class=\"data row0 col4\" >0.889450</td>\n",
              "      <td id=\"T_82694_row0_col5\" class=\"data row0 col5\" >0.889281</td>\n",
              "      <td id=\"T_82694_row0_col6\" class=\"data row0 col6\" >0.888845</td>\n",
              "      <td id=\"T_82694_row0_col7\" class=\"data row0 col7\" >0.883907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_82694_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_82694_row1_col0\" class=\"data row1 col0\" >SVM (RBF, tuned)</td>\n",
              "      <td id=\"T_82694_row1_col1\" class=\"data row1 col1\" >0.896240</td>\n",
              "      <td id=\"T_82694_row1_col2\" class=\"data row1 col2\" >0.003703</td>\n",
              "      <td id=\"T_82694_row1_col3\" class=\"data row1 col3\" >0.892398</td>\n",
              "      <td id=\"T_82694_row1_col4\" class=\"data row1 col4\" >0.898011</td>\n",
              "      <td id=\"T_82694_row1_col5\" class=\"data row1 col5\" >0.895426</td>\n",
              "      <td id=\"T_82694_row1_col6\" class=\"data row1 col6\" >0.895898</td>\n",
              "      <td id=\"T_82694_row1_col7\" class=\"data row1 col7\" >0.891953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_82694_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_82694_row2_col0\" class=\"data row2 col0\" >KNN (k=21, tuned)</td>\n",
              "      <td id=\"T_82694_row2_col1\" class=\"data row2 col1\" >0.886020</td>\n",
              "      <td id=\"T_82694_row2_col2\" class=\"data row2 col2\" >0.005481</td>\n",
              "      <td id=\"T_82694_row2_col3\" class=\"data row2 col3\" >0.885420</td>\n",
              "      <td id=\"T_82694_row2_col4\" class=\"data row2 col4\" >0.889825</td>\n",
              "      <td id=\"T_82694_row2_col5\" class=\"data row2 col5\" >0.889646</td>\n",
              "      <td id=\"T_82694_row2_col6\" class=\"data row2 col6\" >0.889333</td>\n",
              "      <td id=\"T_82694_row2_col7\" class=\"data row2 col7\" >0.885188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_82694_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_82694_row3_col0\" class=\"data row3 col0\" >Random Forest</td>\n",
              "      <td id=\"T_82694_row3_col1\" class=\"data row3 col1\" >0.884070</td>\n",
              "      <td id=\"T_82694_row3_col2\" class=\"data row3 col2\" >0.001485</td>\n",
              "      <td id=\"T_82694_row3_col3\" class=\"data row3 col3\" >0.886889</td>\n",
              "      <td id=\"T_82694_row3_col4\" class=\"data row3 col4\" >0.890912</td>\n",
              "      <td id=\"T_82694_row3_col5\" class=\"data row3 col5\" >0.889214</td>\n",
              "      <td id=\"T_82694_row3_col6\" class=\"data row3 col6\" >0.889745</td>\n",
              "      <td id=\"T_82694_row3_col7\" class=\"data row3 col7\" >0.886417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_82694_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_82694_row4_col0\" class=\"data row4 col0\" >XGBoost</td>\n",
              "      <td id=\"T_82694_row4_col1\" class=\"data row4 col1\" >0.882970</td>\n",
              "      <td id=\"T_82694_row4_col2\" class=\"data row4 col2\" >0.005745</td>\n",
              "      <td id=\"T_82694_row4_col3\" class=\"data row4 col3\" >0.881014</td>\n",
              "      <td id=\"T_82694_row4_col4\" class=\"data row4 col4\" >0.884633</td>\n",
              "      <td id=\"T_82694_row4_col5\" class=\"data row4 col5\" >0.882668</td>\n",
              "      <td id=\"T_82694_row4_col6\" class=\"data row4 col6\" >0.883540</td>\n",
              "      <td id=\"T_82694_row4_col7\" class=\"data row4 col7\" >0.880852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_82694_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_82694_row5_col0\" class=\"data row5 col0\" >LightGBM</td>\n",
              "      <td id=\"T_82694_row5_col1\" class=\"data row5 col1\" >0.878730</td>\n",
              "      <td id=\"T_82694_row5_col2\" class=\"data row5 col2\" >0.002488</td>\n",
              "      <td id=\"T_82694_row5_col3\" class=\"data row5 col3\" >0.878810</td>\n",
              "      <td id=\"T_82694_row5_col4\" class=\"data row5 col4\" >0.884680</td>\n",
              "      <td id=\"T_82694_row5_col5\" class=\"data row5 col5\" >0.881342</td>\n",
              "      <td id=\"T_82694_row5_col6\" class=\"data row5 col6\" >0.882808</td>\n",
              "      <td id=\"T_82694_row5_col7\" class=\"data row5 col7\" >0.878639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_82694_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_82694_row6_col0\" class=\"data row6 col0\" >MLP (Neural Network)</td>\n",
              "      <td id=\"T_82694_row6_col1\" class=\"data row6 col1\" >0.893832</td>\n",
              "      <td id=\"T_82694_row6_col2\" class=\"data row6 col2\" >0.003063</td>\n",
              "      <td id=\"T_82694_row6_col3\" class=\"data row6 col3\" >0.892398</td>\n",
              "      <td id=\"T_82694_row6_col4\" class=\"data row6 col4\" >0.896019</td>\n",
              "      <td id=\"T_82694_row6_col5\" class=\"data row6 col5\" >0.895773</td>\n",
              "      <td id=\"T_82694_row6_col6\" class=\"data row6 col6\" >0.895687</td>\n",
              "      <td id=\"T_82694_row6_col7\" class=\"data row6 col7\" >0.892022</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved: results_summary_v3.csv\n"
          ]
        }
      ],
      "source": [
        "summary_df = pd.DataFrame([\n",
        "    {\n",
        "        \"Model\":                name,\n",
        "        \"CV_MacroF1_Mean\":      r[\"cv_f1_macro_mean\"],\n",
        "        \"CV_MacroF1_Std\":       r[\"cv_f1_macro_std\"],\n",
        "        \"Test_Accuracy\":        r[\"test_accuracy\"],\n",
        "        \"Test_Precision_Macro\": r[\"test_precision_macro\"],\n",
        "        \"Test_Recall_Macro\":    r[\"test_recall_macro\"],\n",
        "        \"Test_F1_Macro\":        r[\"test_f1_macro\"],\n",
        "        \"Test_F1_Weighted\":     r[\"test_f1_weighted\"],\n",
        "    }\n",
        "    for name, r in results.items()\n",
        "])\n",
        "\n",
        "summary_csv_path = os.path.join(OUTPUT_DIR, \"results_summary_v3.csv\")\n",
        "summary_df.to_csv(summary_csv_path, index=False)\n",
        "\n",
        "# Display table\n",
        "display(summary_df.style.highlight_max(\n",
        "    subset=[\"CV_MacroF1_Mean\", \"Test_Accuracy\", \"Test_F1_Macro\"],\n",
        "    color=\"lightgreen\"\n",
        "))\n",
        "print(f\"\\nSaved: results_summary_v3.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIvTnfmSArSm"
      },
      "source": [
        "---\n",
        "## 13. Enhancement Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68734i0gArSn",
        "outputId": "3a857ecb-c86e-417a-d57a-af73947ecba3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ENHANCEMENT SUMMARY\n",
            "============================================================\n",
            "\n",
            "1. SMOTE (Address Imbalance):\n",
            "   Augmented minority classes (e.g. BOMBAY 418 -> 2837 samples)\n",
            "   Applied inside imblearn Pipeline — no data leakage\n",
            "\n",
            "2. PCA (Feature Engineering):\n",
            "   Reduced 16 correlated features -> 4 orthogonal components\n",
            "   Variance retained: 95.1%\n",
            "\n",
            "3. GridSearchCV (Systematic Optimisation):\n",
            "   SVM:  C=10, gamma=0.1\n",
            "   KNN:  k=21, weights=uniform\n",
            "\n",
            "4. Model Expansion (Advanced Models):\n",
            "   Added XGBoost, LightGBM, and MLP (Neural Network)\n",
            "   Total models evaluated: 7\n",
            "\n",
            "============================================================\n",
            "BEST MODEL: SVM (RBF, tuned)\n",
            "CV macro-F1:   0.8962\n",
            "Test macro-F1: 0.8959\n",
            "Test Accuracy: 0.8924\n",
            "============================================================\n",
            "\n",
            "All outputs saved to: /content/output\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"ENHANCEMENT SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\n1. SMOTE (Address Imbalance):\")\n",
        "print(f\"   Augmented minority classes (e.g. BOMBAY {counts_before.min()} -> {counts_after.max()} samples)\")\n",
        "print(f\"   Applied inside imblearn Pipeline — no data leakage\")\n",
        "\n",
        "print(f\"\\n2. PCA (Feature Engineering):\")\n",
        "print(f\"   Reduced {X_train.shape[1]} correlated features -> {n_components_95} orthogonal components\")\n",
        "print(f\"   Variance retained: {cumulative_variance[n_components_95-1]*100:.1f}%\")\n",
        "\n",
        "print(f\"\\n3. GridSearchCV (Systematic Optimisation):\")\n",
        "print(f\"   SVM:  C={best_svm_C}, gamma={best_svm_gamma}\")\n",
        "print(f\"   KNN:  k={best_knn_k}, weights={best_knn_w}\")\n",
        "\n",
        "print(f\"\\n4. Model Expansion (Advanced Models):\")\n",
        "print(f\"   Added XGBoost, LightGBM, and MLP (Neural Network)\")\n",
        "print(f\"   Total models evaluated: {len(results)}\")\n",
        "\n",
        "print(f\"\\n\" + \"=\" * 60)\n",
        "print(f\"BEST MODEL: {best_model_name}\")\n",
        "print(f\"CV macro-F1:   {best['cv_f1_macro_mean']:.4f}\")\n",
        "print(f\"Test macro-F1: {best['test_f1_macro']:.4f}\")\n",
        "print(f\"Test Accuracy: {best['test_accuracy']:.4f}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\nAll outputs saved to: {OUTPUT_DIR}\")\n",
        "print(\"Done!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}